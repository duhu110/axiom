没问题。我们要把这两者拆开来看，分别作为“前端接收端（AI SDK）”和“后端生产端（LangChain）”的独立字典来查阅。

以下是 **Vercel AI SDK UI (Client)** 的主要组件/钩子，以及 **LangChain `astream_events**` 的主要事件类型的详细清单。

---

### 第一部分：Vercel AI SDK UI 主要组件 (Hooks & Primitives)

在 `ai/react` 或 `ai/vue` 等包中，这些是你构建界面时直接操作的核心“元素”。

#### 1. `useChat` (核心 Hook)

* **作用**：这是聊天界面的“大脑”。它管理对话的所有状态（消息列表、输入框、加载状态），并自动处理流式数据的拼接。
* **需要/维护的数据**：
* **Input**：用户输入的字符串。
* **Messages**：一个 `Message[]` 数组（见下文）。
* **Data**：服务端发送的辅助数据（StreamData）。


* **输出行为**：当调用 `handleSubmit` 或 `append` 时，它会向 API 发送请求，并根据返回的 Stream Protocol 更新 `messages` 数组。

#### 2. `Message` (数据对象)

* **作用**：UI 渲染的最小原子单位，代表气泡。
* **数据结构**：
* `id`: 唯一标识符。
* `role`: 角色，枚举值 `'system' | 'user' | 'assistant' | 'data'`。
* `content`: 文本内容（如果是 `'assistant'`，这里是流式生成的文本）。
* `toolInvocations`: **关键字段**，如果不为空，代表这条消息包含工具调用（见下文）。
* `annotations`: 随消息附带的元数据（如 token 统计）。



#### 3. `ToolInvocation` (数据对象 - 属于 Message 的一部分)

* **作用**：描述一个工具调用的完整生命周期。它根据状态不同，UI 表现也不同。
* **数据结构**：
* `toolCallId`: 唯一 ID。
* `toolName`: 工具名称（如 `calculator`）。
* `args`: 工具参数（如 `{ expression: "2+2" }`）。
* **状态分支**：
* **State: 'call'**：仅有上述信息，表示“AI 想要调工具，正在等待结果”。
* **State: 'result'**：增加了 `result` 字段，表示“工具已执行完毕，这是结果”。





#### 4. `useCompletion` (Hook)

* **作用**：用于非对话式的文本生成（如“自动补全”、“文章生成”）。它不维护历史对话记录 (`messages` 数组)，只维护单一的 `completion` 字符串。
* **需要的数据**：Prompt（提示词）。

#### 5. `useObject` (Hook)

* **作用**：用于**结构化数据生成**。它不是生成文本，而是将流式内容实时解析为 JSON 对象。
* **需要的数据**：Zod Schema（定义你想要的 JSON 结构）。
* **输出**：`object` (当前解析出的部分对象)，`isLoading`。

#### 6. `data` (全局流数据)

* **作用**：`useChat` 返回的一个属性。它不是消息，而是与当前对话流相关的通用 JSON 数据列表。
* **数据来源**：服务端通过 `StreamData` 写入的内容（协议中的 `2:` 类型）。
* **典型用途**：存放 RAG 的 Documents (Sources)、状态更新日志。

---

### 第二部分：LangChain `astream_events` (v2) 事件清单

当你调用 `agent.astream_events(inputs, version="v2")` 时，LangChain 会吐出大量细粒度的事件。以下是主要会遇到的事件类型。

#### 1. `on_chat_model_stream`

* **大概是干啥的**：大模型（LLM）正在“吐字”。这是流式输出最密集的事件。
* **什么情况出现**：LLM 生成文本期间，每个 Token 触发一次。
* **关键数据**：
* `data.chunk.content`: 当前这一个 Token 的文本（字符串片段）。
* `data.chunk.tool_call_chunks`: 如果模型正在生成工具调用参数，这里会有部分 JSON 片段。



#### 2. `on_chat_model_start`

* **大概是干啥的**：LLM 收到输入，准备开始工作了。
* **什么情况出现**：调用 LLM API 之前的一瞬间。
* **关键数据**：
* `data.input.messages`: 最终发送给 LLM 的完整 Prompt 历史。
* `metadata`: 模型名称、参数配置。



#### 3. `on_chat_model_end`

* **大概是干啥的**：LLM 说完话了（或者是工具参数生成完了）。
* **什么情况出现**：LLM 输出结束时。
* **关键数据**：
* `data.output.content`: 完整的回复文本。
* `data.output.tool_calls`: 如果模型决定调用工具，这里有完整的工具名和参数。
* `data.output.usage_metadata`: Token 消耗统计。



#### 4. `on_tool_start`

* **大概是干啥的**：代码开始执行某个具体的工具函数。
* **什么情况出现**：Agent 解析出 LLM 的意图后，开始运行本地 Python/JS 函数时。
* **关键数据**：
* `name`: 工具名称（如 `web_search`）。
* `data.input`: 传入工具的具体参数。



#### 5. `on_tool_end`

* **大概是干啥的**：工具函数运行完毕，拿到了结果。
* **什么情况出现**：工具执行成功并返回数据时。
* **关键数据**：
* `name`: 工具名称。
* `data.output`: 工具的返回结果（可能是字符串，也可能是 JSON artifact）。



#### 6. `on_retriever_end` (RAG 专用)

* **大概是干啥的**：检索器（Retriever）找完了文档。
* **什么情况出现**：在 RAG 链中，向量数据库查询结束时。
* **关键数据**：
* `data.output`: 一个 `Document` 对象列表。这是获取 **Sources（引用来源）** 的核心事件。



#### 7. `on_chain_start`

* **大概是干啥的**：进入了一个逻辑块（Runnable）或子图。
* **什么情况出现**：
* 整个 Agent 启动时。
* 进入 LangGraph 的某个 Node 时。


* **关键数据**：
* `name`: 链或节点的名称（如 `Agent` 或 `RetrieveDocuments`）。
* `tags`: 用户自定义的标签（常用于前端过滤显示特定步骤）。



#### 8. `on_chain_end`

* **大概是干啥的**：一个逻辑块执行完毕。
* **什么情况出现**：节点执行完成，准备把输出传给下一个节点时。
* **关键数据**：
* `data.output`: 该节点/链产生的最终结果。



#### 9. `on_custom_event` (自定义事件)

* **大概是干啥的**：开发者在代码里手动触发的事件。
* **什么情况出现**：你在 Python 代码里写了 `dispatch_custom_event(...)`。
* **关键数据**：
* `name`: 你定义的事件名（如 `progress_update`）。
* `data`: 你传递的任意 payload。